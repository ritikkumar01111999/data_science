{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tag_prediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritikkumar01111999/data_science/blob/main/Tag_prediction_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jiR1IqoSlvR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import hamming_loss\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb_qIevHjmdK"
      },
      "source": [
        "# Import data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HljXVUaIjFpk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ADBJBwjjGj7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEnssx2JNSWE"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/tag_recommendation/data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnCgO6vkmpfa"
      },
      "source": [
        "Multi-label classification "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ujPq0LMjmhi"
      },
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uEViyS4kOgM"
      },
      "source": [
        "# load stop words\n",
        "# import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_word = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qreRODqqfGuH"
      },
      "source": [
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KVqW0CdSVRI"
      },
      "source": [
        "def cleanig_data(dataset):\n",
        "  from nltk.corpus import stopwords\n",
        "  dataset.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  dataset = dataset.dropna()\n",
        "  # df['url'] = df['url'].str.lower()\n",
        "  dataset['description'] = dataset['description'].str.lower()\n",
        "  dataset['tags'] = dataset['tags'].str.lower()\n",
        "\n",
        "  def cleanHtml(sentence):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
        "    return cleantext\n",
        "  def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    cleaned = cleaned.strip()\n",
        "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
        "    return cleaned\n",
        "  def keepAlpha(sentence):\n",
        "    alpha_sent = \"\"\n",
        "    for word in sentence.split():\n",
        "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
        "        alpha_sent += alpha_word\n",
        "        alpha_sent += \" \"\n",
        "    alpha_sent = alpha_sent.strip()\n",
        "    return alpha_sent\n",
        "  \n",
        "  token=ToktokTokenizer()\n",
        "  lemma=WordNetLemmatizer()\n",
        "\n",
        "  def lemitizeWords(text):\n",
        "    words=token.tokenize(text)\n",
        "    listLemma=[]\n",
        "    for w in words:\n",
        "        x=lemma.lemmatize(w, pos=\"v\")\n",
        "        listLemma.append(x)\n",
        "    return ' '.join(map(str, listLemma))\n",
        "  \n",
        "  # dataset['description'] = dataset['description'].str.lower()\n",
        "  dataset['description'] = dataset['description'].apply(cleanHtml)\n",
        "  dataset['description'] = dataset['description'].apply(cleanPunc)\n",
        "  dataset['description'] = dataset['description'].apply(keepAlpha)\n",
        "  \n",
        "  dataset['description'] = dataset['description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "  dataset['description'] = dataset['description'].apply(lambda x: lemitizeWords(x))\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKJi1NbySVN3"
      },
      "source": [
        "data_result = cleanig_data(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDvl3FFUkdtZ"
      },
      "source": [
        "data_result.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6JBqEeGeFgO"
      },
      "source": [
        "data_result['description'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XO067PhPcv-"
      },
      "source": [
        "**Tag Processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFu3S99FlGu_"
      },
      "source": [
        "def tag_processing(dataset):\n",
        "  dataset['new_tags'] = dataset[\"tags\"].apply(lambda x: x.split())\n",
        "  all_tags = [item for sublist in dataset['new_tags'].values for item in sublist]\n",
        "  print('TOtal number of tags are', len(all_tags))\n",
        "  # getting unique set\n",
        "  my_set = set(all_tags)\n",
        "  unique_tags = list(my_set)\n",
        "  print('Total number of unique are',len(unique_tags))\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wovxNjICmAZQ"
      },
      "source": [
        "cleaned_data = tag_processing(data_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqqH7XKrPji2"
      },
      "source": [
        "****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1Eyt-tvQTxH"
      },
      "source": [
        "**train - test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEOYCA1Cifke"
      },
      "source": [
        "x_train=cleaned_data['description'][:3000]\n",
        "x_test=cleaned_data['description'][3000:]\n",
        "\n",
        "y_train = cleaned_data['tags'][:3000]\n",
        "y_test =  cleaned_data['tags'][3000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmoAuuE4QtTT"
      },
      "source": [
        "**Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQQRvQS8QSAp"
      },
      "source": [
        "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(), binary='true')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpuMXjFshqHw"
      },
      "source": [
        "multilabel_y_train = vectorizer.fit_transform(y_train)\n",
        "multilabel_y_test = vectorizer.fit_transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6LDZUGchp7P"
      },
      "source": [
        "vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUYVL0i1hp1_"
      },
      "source": [
        " print(multilabel_y_test.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C7xjXdLhpkr"
      },
      "source": [
        "vectorizer = TfidfVectorizer(smooth_idf=True, norm=\"l2\", \\\n",
        "                             tokenizer = lambda x: x.split(), sublinear_tf=False, ngram_range=(1,3))\n",
        "x_train_multilabel = vectorizer.fit_transform(x_train)\n",
        "x_test_multilabel = vectorizer.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OxwXPL8hpfV"
      },
      "source": [
        "vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iH8ograhpTt"
      },
      "source": [
        "print(\"Dimensions of train data X:\",x_train_multilabel.shape, \"Y :\",multilabel_y_train.shape)\n",
        "print(\"Dimensions of test data X:\",x_test_multilabel.shape,\"Y:\",multilabel_y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBfTi5v_RGFs"
      },
      "source": [
        "**Training Model with logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3CWqii2hpN9"
      },
      "source": [
        "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.00001, penalty='l1'), n_jobs=-1)\n",
        "classifier.fit(x_train_multilabel,multilabel_y_train )\n",
        "predictions = classifier.predict (x_test_multilabel)\n",
        "predictions_train = classifier.predict (x_train_multilabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxeDRmx9HubG"
      },
      "source": [
        "print(predictions.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJiTlf4aSVIC"
      },
      "source": [
        "**Evaluating Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QbPkj09LBRv"
      },
      "source": [
        "y_true = multilabel_y_test.toarray()\n",
        "y_logits = predictions.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTaBJYzLcVMD"
      },
      "source": [
        "def result_check(x, y):\n",
        "     count = 0\n",
        "     for i in range(len(x)):\n",
        "         if x[i] == y[i]:\n",
        "             count += 1\n",
        "     result = count / len(x)\n",
        "     return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjlN7kOcc5iM"
      },
      "source": [
        "print(result_check(y_true[2],y_logits[2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oD5WKQMda8M"
      },
      "source": [
        "def subset_accuracy(y_true,y_predict,threshold):\n",
        "  count = 0\n",
        "  for j in range(len(y_true)):\n",
        "    if result_check(y_true[j] , y_predict[j]) >= threshold:\n",
        "      count = count + 1\n",
        "  accuracy = count / len(y_true)\n",
        "  return accuracy\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulGrJYoBY-jE"
      },
      "source": [
        "**subset accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O57EsxXUZZHw"
      },
      "source": [
        "threshold_list = [1,.9,.8,.7,.6,.5]\n",
        "for i in threshold_list:\n",
        "  print(f'for threshold {i} accuracy is = ',subset_accuracy(y_true,y_logits,threshold=i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X5kM20Qz0Rq"
      },
      "source": [
        "print(\"train Accuracy :\",metrics.accuracy_score(multilabel_y_train, predictions_train))\n",
        "print(\"test Accuracy :\",metrics.accuracy_score(multilabel_y_test, predictions))\n",
        "print(\"Hamming loss \",metrics.hamming_loss(multilabel_y_test,predictions))\n",
        "\n",
        "\n",
        "precision = precision_score(multilabel_y_test, predictions, average='micro')\n",
        "recall = recall_score(multilabel_y_test, predictions, average='micro')\n",
        "f1 = f1_score(multilabel_y_test, predictions, average='micro')\n",
        " \n",
        "print(\"Micro-average quality numbers\")\n",
        "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
        "\n",
        "precision = precision_score(multilabel_y_test, predictions, average='macro')\n",
        "recall = recall_score(multilabel_y_test, predictions, average='macro')\n",
        "f1 = f1_score(multilabel_y_test, predictions, average='macro')\n",
        " \n",
        "print(\"Macro-average quality numbers\")\n",
        "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d42I-gVV0rOW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C-eoUY20rIX"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5JZUMc10rB5"
      },
      "source": [
        "xgb_estimator = xgb.XGBClassifier(objective='binary:logistic')\n",
        "multilabel_model = OneVsRestClassifier(xgb_estimator)\n",
        "multilabel_model.fit(x_train_multilabel,multilabel_y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F1moGv90q8W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhBgBb5gjmn9"
      },
      "source": [
        "# Preprocessing of text data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq0byy1HjmrS"
      },
      "source": [
        "- bag of words\n",
        "- tfidf vectorization\n",
        "- word2vec\n",
        "- own technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K2R9CrajmvB"
      },
      "source": [
        "Model with hyperparameter tuning\n",
        " - bag of words\n",
        " - tfidf vec.\n",
        " - word2vec\n",
        " - \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkKfrSpJjmy3"
      },
      "source": [
        "For every Model \n",
        " - train accuracy in graph\n",
        " - test accuracy in graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgoZu-Umjm1t"
      },
      "source": [
        "pretty table for all models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgVXN5eaolx-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCRWqA1-olng"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nn8UuI0ole8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI4CZPt3VFB4"
      },
      "source": [
        "**Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lp6ELPbVJLx"
      },
      "source": [
        "def avg_jacard(y_true,y_pred):\n",
        "    '''\n",
        "    see https://en.wikipedia.org/wiki/Multi-label_classification#Statistics_and_evaluation_metrics\n",
        "    '''\n",
        "    jacard = np.minimum(y_true,y_pred).sum(axis=1) / np.maximum(y_true,y_pred).sum(axis=1)\n",
        "    \n",
        "    return jacard.mean()*100\n",
        "\n",
        "def print_score_test(y_pred, clf):\n",
        "    print(\"Clf: \", clf.__class__.__name__)\n",
        "    print(\"Jacard score: {}\".format(avg_jacard(y_test, y_pred)))\n",
        "    print(\"Hamming loss: {}\".format(hamming_loss(y_pred, y_test)*100))\n",
        "    print(\"---\")  \n",
        "def print_score_train(y_pred, clf):\n",
        "    print(\"Clf: \", clf.__class__.__name__)\n",
        "    print(\"Jacard score: {}\".format(avg_jacard(y_train, y_pred)))\n",
        "    print(\"Hamming loss: {}\".format(hamming_loss(y_pred, y_train)*100))\n",
        "    print(\"---\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc-QgnfQVJIO"
      },
      "source": [
        "dummy = DummyClassifier()\n",
        "sgd = SGDClassifier()\n",
        "lr = LogisticRegression()\n",
        "mn = MultinomialNB()\n",
        "svc = LinearSVC()\n",
        "perceptron = Perceptron()\n",
        "pac = PassiveAggressiveClassifier()\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "for classifier in [dummy, sgd, lr, mn, svc, perceptron, pac , rfc]:\n",
        "    clf = OneVsRestClassifier(classifier)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print_score_test(y_pred, classifier)\n",
        "    print('accuracy_score:',accuracy_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyOn5SZsgxye"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGRVp0tkgxj8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjZjLsVxgxZs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AlHg8O8gxP6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiEyJ7z0vYIM"
      },
      "source": [
        "**Training model using  XGBOOSt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKsfDn5svXm8"
      },
      "source": [
        "xgb_estimator = xgb.XGBClassifier(objective='binary:logistic')\n",
        "multilabel_model = OneVsRestClassifier(xgb_estimator)\n",
        "multilabel_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeyr6SDqxBcE"
      },
      "source": [
        "print('Accuracy on train data: {:.1f}%'.format(accuracy_score(y_train, multilabel_model.predict(X_train))*100))\n",
        "print('Accuracy on test data: {:.1f}%'.format(accuracy_score(y_test, multilabel_model.predict(X_test))*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiUpSb62ZPzm"
      },
      "source": [
        "print_score_test(multilabel_model.predict(X_test),multilabel_model )\n",
        "print(classification_report(y_test, multilabel_model.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_Qx3IaSdlK3"
      },
      "source": [
        "**hyperparameter tunig using SVC and kernel**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq_vQulhZJZx"
      },
      "source": [
        "model_to_set = OneVsRestClassifier(SVC(kernel=\"rbf\"))\n",
        "\n",
        "parameters = {\n",
        "    \"estimator__C\": [1,2,3,4,5,6,7,8,9],\n",
        "    \"estimator__kernel\": [\"poly\",\"rbf\",\"linear\"],\n",
        "    \"estimator__degree\":[0,1, 2, 3, 4],\n",
        "    \n",
        "}\n",
        "\n",
        "model_tunning = GridSearchCV(model_to_set, param_grid=parameters,\n",
        "                             scoring='accuracy',cv = 3)\n",
        "\n",
        "model_tunning.fit(X_cv, y_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUXx0B7-osvw"
      },
      "source": [
        "model_tunning.best_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1pJfAAbZJSE"
      },
      "source": [
        "ad=model_tunning.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm8Fpn4sf8pE"
      },
      "source": [
        "ad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXUv3foOZJPE"
      },
      "source": [
        "ad.fit(X_train, y_train)\n",
        "y_pred = ad.predict(X_train)\n",
        "print(\"Accuracy = \",accuracy_score(y_train,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxp_8nXndL9T"
      },
      "source": [
        "y_pred = ad.predict(X_test)\n",
        "print(\"Accuracy = \",accuracy_score(y_test,y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVJhJeLNdeFS"
      },
      "source": [
        "print_score_test(y_pred, ad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63naYkWMd8Ya"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWlyKeS1d1Mb"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykbsra0XqqZS"
      },
      "source": [
        "**hyperparameter tuning using linearSVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU_JtJq4WITP"
      },
      "source": [
        "param_grid = {'estimator__C':[1,2,3,4,5,6,7,8,9] }\n",
        "\n",
        "svc = OneVsRestClassifier(LinearSVC())\n",
        "CV_svc = model_selection.GridSearchCV(estimator=svc, \n",
        "                                      param_grid=param_grid, cv= 5, scoring = 'accuracy')\n",
        "CV_svc.fit(X_cv, y_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvdkEzFFWINt"
      },
      "source": [
        "best_model = CV_svc.best_estimator_\n",
        "\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4NJPwXDuUX9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2u8YLGEuWQ0"
      },
      "source": [
        "best_model.fit(X_train, y_train)\n",
        "y_pred = best_model.predict(X_train)\n",
        "print(\"Accuracy = \",accuracy_score(y_train,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TloFrMsmueKw"
      },
      "source": [
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Accuracy = \",accuracy_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMnirh9a1YZh"
      },
      "source": [
        "print_score_test(y_pred, best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqXSwfpTfMZy"
      },
      "source": [
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdbVFj4igxoA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOCUhJFlXM-1"
      },
      "source": [
        "How to solve Multi - label classification Problem - https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWOPS8vhi8sZ"
      },
      "source": [
        "Reason to use CV in model  -https://towardsdatascience.com/5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9mB-qrd_0Rj"
      },
      "source": [
        "Nested cross validation  : https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK6HXJm6nxhA"
      },
      "source": [
        "Reference\n",
        "\n",
        "https://www.kaggle.com/miljan/predicting-tags-for-stackoverflow"
      ]
    }
  ]
}